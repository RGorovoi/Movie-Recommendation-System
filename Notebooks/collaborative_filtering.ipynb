{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ast # Used sometimes if json.loads fails unexpectedly\n",
        "\n",
        "# --- PHASE 1: Loading, Merging, and Initial Cleaning ---\n",
        "\n",
        "# Merging the TMDB 5000 Movie Dataset and TMDB 5000 Credits Dataset\n",
        "movies_df = pd.read_csv('tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('tmdb_5000_credits.csv')\n",
        "\n",
        "# 1. Merge the two DataFrames on 'id' (from movies_df) and 'movie_id' (from credits_df)\n",
        "merged_df = pd.merge(movies_df, credits_df, left_on='id', right_on='movie_id', how='inner')\n",
        "\n",
        "# 2. Drop redundant and unnecessary columns\n",
        "merged_df.drop('movie_id', axis=1, inplace=True) # Redundant ID column\n",
        "merged_df.drop('title_y', axis=1, inplace=True) # Redundant title from credits file\n",
        "merged_df.drop('original_title', axis=1, inplace=True) # Keeping only English 'title'\n",
        "\n",
        "# 3. Rename columns for clarity\n",
        "merged_df = merged_df.rename(columns={'title_x': 'title'})\n",
        "\n",
        "# 4. Critical: Ensure 'id' remains a column, NOT an index.\n",
        "if merged_df.index.name == 'id':\n",
        "    merged_df.reset_index(inplace=True)\n",
        "\n",
        "# 5. Handle simple missing values\n",
        "merged_df['tagline'] = merged_df['tagline'].fillna('')\n",
        "merged_df['overview'] = merged_df['overview'].fillna('')\n",
        "merged_df['homepage'] = merged_df['homepage'].fillna('')\n",
        "\n",
        "# 6. Handle release_date and runtime\n",
        "merged_df['release_date'] = pd.to_datetime(merged_df['release_date'], errors='coerce')\n",
        "# Drop rows where release_date failed (1 missing row in original data)\n",
        "merged_df.dropna(subset=['release_date'], inplace=True)\n",
        "\n",
        "# Fill missing runtime with the median value\n",
        "merged_df['runtime'] = merged_df['runtime'].fillna(merged_df['runtime'].median())\n",
        "\n",
        "print(\"Initial Merging and Cleaning complete.\")\n",
        "print(f\"Current TMDB ID column type: {merged_df['id'].dtype}\")\n",
        "\n",
        "# --- PHASE 2: JSON Parsing and Flattening ---\n",
        "\n",
        "# Define a safe parser function for JSON columns (using ast.literal_eval as a fallback for safety)\n",
        "def safe_json_parse(json_string):\n",
        "    try:\n",
        "        # Tries standard JSON load\n",
        "        return json.loads(json_string)\n",
        "    except:\n",
        "        # Fallback for poorly formatted strings\n",
        "        try:\n",
        "            return ast.literal_eval(json_string)\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "# Helper function to extract and join names from JSON list\n",
        "def extract_names(json_list):\n",
        "    return ', '.join([item['name'] for item in json_list])\n",
        "\n",
        "# --- Apply Parsers ---\n",
        "\n",
        "# 1. Genres\n",
        "merged_df['genres'] = merged_df['genres'].apply(safe_json_parse).apply(extract_names)\n",
        "\n",
        "# 2. Keywords\n",
        "merged_df['keywords'] = merged_df['keywords'].apply(safe_json_parse).apply(extract_names)\n",
        "\n",
        "# 3. Production Companies\n",
        "merged_df['production_companies'] = merged_df['production_companies'].apply(safe_json_parse).apply(extract_names)\n",
        "\n",
        "# 4. Spoken Languages\n",
        "merged_df['spoken_languages'] = merged_df['spoken_languages'].apply(safe_json_parse).apply(extract_names)\n",
        "\n",
        "# 5. Production Countries\n",
        "merged_df['production_countries'] = merged_df['production_countries'].apply(safe_json_parse).apply(extract_names)\n",
        "\n",
        "# 6. Cast (Top 6 actors/actresses)\n",
        "def parse_cast_top_n(x, n=6):\n",
        "    cast = safe_json_parse(x)\n",
        "    return ', '.join([actor['name'] for actor in cast[:n]])\n",
        "merged_df['cast'] = merged_df['cast'].apply(parse_cast_top_n)\n",
        "\n",
        "# 7. Crew (All crew members with job description)\n",
        "def parse_crew_full(x):\n",
        "    crew = safe_json_parse(x)\n",
        "    return ', '.join([f\"{member['name']} ({member['job']})\" for member in crew])\n",
        "merged_df['crew'] = merged_df['crew'].apply(parse_crew_full)\n",
        "\n",
        "# --- PHASE 3: Final Save ---\n",
        "\n",
        "output_filename = 'clean_parsed_tmdb_5000.csv'\n",
        "\n",
        "# FINAL CHECK: Ensure 'id' is included in the saved file.\n",
        "merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully created Clean TMDB Data.\")\n",
        "print(f\"Saved to: {output_filename}\")\n",
        "print(f\"Final DataFrame shape: {merged_df.shape}\")\n",
        "print(f\"The 'id' column is successfully preserved as a column.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0kcm4lKn3sz",
        "outputId": "a19d187e-94c6-4657-82ab-4f9fce18c6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Merging and Cleaning complete.\n",
            "Current TMDB ID column type: int64\n",
            "\n",
            "Successfully created Clean TMDB Data.\n",
            "Saved to: clean_parsed_tmdb_5000.csv\n",
            "Final DataFrame shape: (4802, 21)\n",
            "The 'id' column is successfully preserved as a column.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files # Used for displaying the files sidebar upload utility (optional, but helpful for context)\n",
        "\n",
        "# --- Step 1: Load Data ---\n",
        "LINKS_FILE = 'links.csv'\n",
        "RATINGS_FILE = 'ratings.csv'\n",
        "OUTPUT_FILE = 'ml_ratings_with_tmdb_id.csv'\n",
        "\n",
        "try:\n",
        "    # Read files directly from the current Colab directory\n",
        "    links_df = pd.read_csv(LINKS_FILE)\n",
        "    ratings_df = pd.read_csv(RATINGS_FILE)\n",
        "    print(\"MovieLens datasets loaded successfully from the Colab environment.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Could not find one or both files ({LINKS_FILE}, {RATINGS_FILE}).\")\n",
        "    print(\"Please ensure the files are uploaded to the root directory of your Colab session.\")\n",
        "    # Exit execution if files are missing\n",
        "    exit()\n",
        "\n",
        "# --- Step 2: Clean and Prepare Links Data ---\n",
        "# links.csv contains movieId, imdbId, tmdbId.\n",
        "# We need 'movieId' to link with ratings and 'tmdbId' to link with the TMDB 5000 dataset.\n",
        "\n",
        "# Drop rows where tmdbId is missing, as we need this ID for joining with TMDB 5000.\n",
        "links_df.dropna(subset=['tmdbId'], inplace=True)\n",
        "\n",
        "# Convert tmdbId to integer type (it's often stored as float due to NaNs)\n",
        "links_df['tmdbId'] = links_df['tmdbId'].astype(int)\n",
        "\n",
        "# Select only the necessary columns\n",
        "links_cleaned = links_df[['movieId', 'tmdbId']]\n",
        "print(f\"Links data cleaned. Retained {links_cleaned.shape[0]} records with valid TMDB IDs.\")\n",
        "\n",
        "# --- Step 3: Clean and Prepare Ratings Data ---\n",
        "# ratings.csv contains userId, movieId, rating, timestamp.\n",
        "# For collaborative filtering, we primarily need userId, movieId, and rating.\n",
        "ratings_cleaned = ratings_df[['userId', 'movieId', 'rating']]\n",
        "print(f\"Ratings data cleaned. Retained {ratings_cleaned.shape[0]} rating records.\")\n",
        "\n",
        "# --- Step 4: Merge DataFrames ---\n",
        "# Merge the ratings data with the TMDB ID based on the common 'movieId'.\n",
        "# An inner merge ensures we only keep ratings for movies that have a valid tmdbId in the links file.\n",
        "merged_ratings_tmdb = pd.merge(\n",
        "    ratings_cleaned,\n",
        "    links_cleaned,\n",
        "    on='movieId',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Rename the tmdbId column to 'id' to match the column name in the 'clean_parsed_tmdb_5000.csv'\n",
        "merged_ratings_tmdb.rename(columns={'tmdbId': 'id'}, inplace=True)\n",
        "\n",
        "print(\"\\nMovieLens Ratings successfully merged with TMDB ID.\")\n",
        "print(f\"Final merged dataset shape: {merged_ratings_tmdb.shape}\")\n",
        "print(\"First 5 rows of the merged data:\")\n",
        "print(merged_ratings_tmdb.head())\n",
        "\n",
        "# --- Step 5: Save the Result ---\n",
        "# Save the new DataFrame containing userId, movieId, rating, and the TMDB 'id'.\n",
        "merged_ratings_tmdb.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"\\nSuccessfully saved the final ratings-to-TMDB-ID mapping file to: {OUTPUT_FILE}\")\n",
        "print(\"This file can now be used for collaborative filtering or merged with your TMDB 5000 movie features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kNFTYpBrscM",
        "outputId": "ea22e0ad-14ae-49c1-ce40-b68c2170ac18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MovieLens datasets loaded successfully from the Colab environment.\n",
            "Links data cleaned. Retained 9734 records with valid TMDB IDs.\n",
            "Ratings data cleaned. Retained 100836 rating records.\n",
            "\n",
            "MovieLens Ratings successfully merged with TMDB ID.\n",
            "Final merged dataset shape: (100823, 4)\n",
            "First 5 rows of the merged data:\n",
            "   userId  movieId  rating     id\n",
            "0       1        1     4.0    862\n",
            "1       1        3     4.0  15602\n",
            "2       1        6     4.0    949\n",
            "3       1       47     5.0    807\n",
            "4       1       50     5.0    629\n",
            "\n",
            "Successfully saved the final ratings-to-TMDB-ID mapping file to: ml_ratings_with_tmdb_id.csv\n",
            "This file can now be used for collaborative filtering or merged with your TMDB 5000 movie features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Flatten, Add, Concatenate, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Configuration ---\n",
        "RATINGS_FILE = 'ml_ratings_with_tmdb_id.csv'\n",
        "LATENT_DIM = 50\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "SEED = 42\n",
        "REG_L2 = 0.005\n",
        "\n",
        "# Ensure reproducibility\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "try:\n",
        "    ratings_df = pd.read_csv(RATINGS_FILE)\n",
        "    # Use MovieLens movieId for encoding, as it's the original identifier for rating records\n",
        "    ratings = ratings_df[['userId', 'movieId', 'rating']]\n",
        "except FileNotFoundError:\n",
        "    print(f\"File {RATINGS_FILE} not found. Using a smaller default dataset for demonstration.\")\n",
        "    data_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small/ratings.csv\"\n",
        "    ratings = pd.read_csv(data_url)\n",
        "    ratings = ratings[['userId', 'movieId', 'rating']]\n",
        "\n",
        "# --- 2. Prepare Data and Encoding ---\n",
        "# Convert original IDs to category codes (0 to N-1) for embedding layer indexing\n",
        "user_ids = ratings['userId'].astype('category').cat.codes\n",
        "movie_ids = ratings['movieId'].astype('category').cat.codes\n",
        "\n",
        "# Create mapping dictionaries to get original IDs back later\n",
        "user_map = dict(enumerate(ratings['userId'].astype('category').cat.categories))\n",
        "movie_map = dict(enumerate(ratings['movieId'].astype('category').cat.categories))\n",
        "\n",
        "num_users = len(user_ids.unique())\n",
        "num_movies = len(movie_ids.unique())\n",
        "global_mean = ratings['rating'].mean() # Calculate Global Mean (mu)\n",
        "\n",
        "X = pd.DataFrame({'user_id': user_ids, 'movie_id': movie_ids})\n",
        "y = ratings['rating'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "print(f\"Global Mean Rating: {global_mean:.4f}\")\n",
        "print(f\"Using L2 Regularization factor: {REG_L2}\")\n",
        "\n",
        "# --- 3. Build Keras Matrix Factorization Model with Biases and Regularization ---\n",
        "def build_svd_model_with_biases(num_users, num_movies, latent_dim, reg_l2, global_mean):\n",
        "\n",
        "    # --- Shared Components: User and Movie Inputs ---\n",
        "    user_input = Input(shape=(1,), name='user_input')\n",
        "    movie_input = Input(shape=(1,), name='movie_input')\n",
        "\n",
        "    # --- 1. User and Movie Embeddings (Latent Factors P and Q) with L2 Regularization ---\n",
        "    # User Embeddings (P)\n",
        "    user_embedding = Embedding(input_dim=num_users,\n",
        "                               output_dim=latent_dim,\n",
        "                               embeddings_regularizer=l2(reg_l2),\n",
        "                               name='user_factors')(user_input)\n",
        "    user_vec = Flatten(name='flatten_user')(user_embedding)\n",
        "\n",
        "    # Movie Embeddings (Q)\n",
        "    movie_embedding = Embedding(input_dim=num_movies,\n",
        "                                 output_dim=latent_dim,\n",
        "                                 embeddings_regularizer=l2(reg_l2),\n",
        "                                 name='movie_factors')(movie_input)\n",
        "    movie_vec = Flatten(name='flatten_movie')(movie_embedding)\n",
        "\n",
        "    # --- 2. User and Movie Biases (B_u and B_i) with L2 Regularization ---\n",
        "    # User Bias (b_u) - output_dim=1 for a scalar bias\n",
        "    user_bias = Embedding(input_dim=num_users,\n",
        "                              output_dim=1,\n",
        "                              embeddings_regularizer=l2(reg_l2),\n",
        "                              name='user_bias')(user_input)\n",
        "    user_bias_flat = Flatten(name='flatten_user_bias')(user_bias)\n",
        "\n",
        "    # Movie Bias (b_i) - output_dim=1 for a scalar bias\n",
        "    movie_bias = Embedding(input_dim=num_movies,\n",
        "                            output_dim=1,\n",
        "                            embeddings_regularizer=l2(reg_l2),\n",
        "                            name='movie_bias')(movie_input)\n",
        "    movie_bias_flat = Flatten(name='flatten_movie_bias')(movie_bias)\n",
        "\n",
        "    # --- 3. Prediction Formulation (SVD/Matrix Factorization Formula) ---\n",
        "    # R_hat = mu + b_u + b_i + P_u * Q_i^T\n",
        "\n",
        "    # P_u * Q_i^T (Dot product of latent factors)\n",
        "    latent_dot_product = Dot(axes=1, name='latent_dot_product')([user_vec, movie_vec])\n",
        "\n",
        "    # A layer representing the constant global mean (mu)\n",
        "    global_mean_layer = Lambda(lambda x: x + global_mean, name='global_mean_add')(latent_dot_product)\n",
        "\n",
        "    # Add the biases to the latent dot product and global mean\n",
        "    output = Add(name='predicted_rating')([global_mean_layer, user_bias_flat, movie_bias_flat])\n",
        "\n",
        "    # Build the model\n",
        "    model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(0.001),\n",
        "                  loss='mse',\n",
        "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='RMSE'), 'mae']) # Added MAE to metrics\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and summarize the enhanced model\n",
        "model_svd = build_svd_model_with_biases(num_users, num_movies, LATENT_DIM, REG_L2, global_mean)\n",
        "model_svd.summary()\n",
        "\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "print(\"\\n--- Starting Enhanced Model Training ---\")\n",
        "\n",
        "# Train the model\n",
        "history = model_svd.fit(\n",
        "    [X_train['user_id'], X_train['movie_id']],\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    validation_data=([X_test['user_id'], X_test['movie_id']], y_test)\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "metrics = model_svd.evaluate([X_test['user_id'], X_test['movie_id']], y_test, verbose=0)\n",
        "loss = metrics[0] # MSE\n",
        "rmse = metrics[1] # RMSE\n",
        "mae = metrics[2] # MAE\n",
        "\n",
        "print(f\"Final Test RMSE (Enhanced Model): {rmse:.4f}\")\n",
        "print(f\"Final Test MAE (Enhanced Model): {mae:.4f}\")\n",
        "print(f\"Final Test MSE (Loss): {loss:.4f}\")\n",
        "\n",
        "\n",
        "# --- 5. Make a Prediction ---\n",
        "original_user_id = 1\n",
        "original_movie_id = 302\n",
        "\n",
        "try:\n",
        "    encoded_user_id = user_ids[ratings['userId'] == original_user_id].iloc[0]\n",
        "    encoded_movie_id = movie_ids[ratings['movieId'] == original_movie_id].iloc[0]\n",
        "except IndexError:\n",
        "    print(f\"\\nUser ID {original_user_id} or Movie ID {original_movie_id} not found in the training data.\")\n",
        "    encoded_user_id = X_test['user_id'].iloc[0]\n",
        "    encoded_movie_id = X_test['movie_id'].iloc[0]\n",
        "    original_user_id = user_map[encoded_user_id]\n",
        "    original_movie_id = movie_map[encoded_movie_id]\n",
        "    print(f\"Using test example: User ID {original_user_id}, Movie ID {original_movie_id}\")\n",
        "\n",
        "user_input_array = np.array([encoded_user_id])\n",
        "movie_input_array = np.array([encoded_movie_id])\n",
        "\n",
        "predicted_rating = model_svd.predict([user_input_array, movie_input_array])[0][0]\n",
        "\n",
        "print(f\"\\n--- Specific Rating Prediction (Enhanced SVD Model) ---\")\n",
        "print(f\"Predicted rating for User ID **{original_user_id}** and Movie ID **{original_movie_id}**: **{predicted_rating:.4f}**\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0PXgVwDRI6pc",
        "outputId": "20ae27f9-afbb-4a71-855d-f38fbc3e0cd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Mean Rating: 3.5016\n",
            "Using L2 Regularization factor: 0.005\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m30,500\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_factors       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m485,800\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_user        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_movie       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ movie_factors[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ latent_dot_product  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ flatten_user[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDot\u001b[0m)               │                   │            │ flatten_movie[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_bias           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m610\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_bias          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │      \u001b[38;5;34m9,716\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_mean_add     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ latent_dot_produ… │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_user_bias   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_bias[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_movie_bias  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ movie_bias[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ predicted_rating    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_mean_add[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ flatten_user_bia… │\n",
              "│                     │                   │            │ flatten_movie_bi… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,500</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_factors       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">485,800</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_user        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_movie       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ latent_dot_product  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_user[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               │                   │            │ flatten_movie[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_bias           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ movie_bias          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,716</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_mean_add     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ latent_dot_produ… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_user_bias   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_movie_bias  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ predicted_rating    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_mean_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ flatten_user_bia… │\n",
              "│                     │                   │            │ flatten_movie_bi… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m526,626\u001b[0m (2.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,626</span> (2.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,626\u001b[0m (2.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,626</span> (2.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Enhanced Model Training ---\n",
            "Epoch 1/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - RMSE: 1.0197 - loss: 1.1776 - mae: 0.8123 - val_RMSE: 0.9785 - val_loss: 0.9928 - val_mae: 0.7767\n",
            "Epoch 2/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9768 - loss: 0.9945 - mae: 0.7764 - val_RMSE: 0.9672 - val_loss: 0.9859 - val_mae: 0.7667\n",
            "Epoch 3/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9687 - loss: 0.9904 - mae: 0.7696 - val_RMSE: 0.9646 - val_loss: 0.9853 - val_mae: 0.7647\n",
            "Epoch 4/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - RMSE: 0.9669 - loss: 0.9900 - mae: 0.7682 - val_RMSE: 0.9640 - val_loss: 0.9852 - val_mae: 0.7642\n",
            "Epoch 5/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9664 - loss: 0.9900 - mae: 0.7679 - val_RMSE: 0.9638 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 6/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7678 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 7/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 8/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 9/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 10/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 11/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 12/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 13/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 14/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 15/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 16/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 17/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 18/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 19/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "Epoch 20/20\n",
            "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
            "\n",
            "--- Training Complete ---\n",
            "Final Test RMSE (Enhanced Model): 0.9637\n",
            "Final Test MAE (Enhanced Model): 0.7641\n",
            "Final Test MSE (Loss): 0.9853\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\n",
            "--- Specific Rating Prediction (Enhanced SVD Model) ---\n",
            "Predicted rating for User ID **1** and Movie ID **302**: **3.7455**\n"
          ]
        }
      ]
    }
  ]
}